{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e2cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing Pipeline for Molecular Solubility Prediction\n",
    "# ==============================================================\n",
    "#\n",
    "# This notebook implements a comprehensive preprocessing pipeline for molecular datasets\n",
    "# including data loading, splitting, feature generation, and applicability domain analysis.\n",
    "#\n",
    "# Key Features:\n",
    "# - Multiple molecular dataset loading\n",
    "# - Various data splitting strategies (random, scaffold, chemical space, etc.)\n",
    "# - Molecular descriptor and fingerprint generation\n",
    "# - Applicability Domain (AD) analysis\n",
    "# - Visualization and statistical analysis\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e7a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom preprocessing and QSAR analysis modules\n",
    "# These modules provide:\n",
    "# - Data loading utilities\n",
    "# - Molecular feature extraction\n",
    "# - Data splitting strategies\n",
    "# - Applicability domain analysis\n",
    "# - Statistical metrics and visualizations\n",
    "\n",
    "from extra_code.preprocess import *\n",
    "from extra_code.qsar_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0e4472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all molecular datasets from the data directory\n",
    "# ==================================================\n",
    "#\n",
    "# The load_data() function automatically:\n",
    "# 1. Scans the data/ directory for CSV files\n",
    "# 2. Loads molecular datasets containing SMILES and solubility values\n",
    "# 3. Returns a dictionary with dataset names as keys and polars DataFrames as values\n",
    "#\n",
    "# IMPORTANT: We exclude 'train' and 'test' directories to prevent loading pre-split data\n",
    "\n",
    "# Load all data files - simple and clean!\n",
    "# Note: load_data() should exclude 'data/' directory to avoid loading train/test splits\n",
    "df_dict = load_data()\n",
    "\n",
    "# Verify that 'train' and 'test' are not loaded as datasets\n",
    "if 'train' in df_dict or 'test' in df_dict:\n",
    "    print(\"‚ö†Ô∏è WARNING: 'train' or 'test' found in datasets. Removing...\")\n",
    "    df_dict.pop('train', None)\n",
    "    df_dict.pop('test', None)\n",
    "    print(\"‚úì Cleaned dataset dictionary\")\n",
    "\n",
    "print(f\"\\nüìä Loaded {len(df_dict)} datasets: {list(df_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5430a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the loaded dataset names\n",
    "# These are the molecular solubility datasets available for analysis\n",
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af31c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test-only datasets\n",
    "# ========================\n",
    "#\n",
    "# Some datasets are reserved exclusively for testing to evaluate model generalization.\n",
    "# These datasets will NOT be used during training or hyperparameter optimization.\n",
    "#\n",
    "# Current test-only datasets:\n",
    "# - SAMPL: SAMPL challenge dataset\n",
    "# - Lipophilicity: Lipophilicity dataset \n",
    "# - curated-solubility-dataset: Curated solubility collection\n",
    "# - BigSolDB: Large solubility database\n",
    "\n",
    "# Define test-only datasets (if any)\n",
    "# These datasets will only be used for testing, not training\n",
    "test_only_datasets = ['SAMPL', 'Lipophilicity', 'curated-solubility-dataset', 'BigSolDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18fb826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Analysis Pipeline Configuration\n",
    "# ===================================\n",
    "#\n",
    "# This section sets up the main preprocessing and analysis pipeline.\n",
    "# \n",
    "# Key Components:\n",
    "# 1. Output Directory Management\n",
    "#    - All results saved to result/1_preprocess_enhanced/\n",
    "#    - Original data in data/ directory is NEVER modified\n",
    "#    - Option to force full re-analysis or use existing splits\n",
    "#\n",
    "# 2. Analysis Modes:\n",
    "#    - Full Analysis: Complete train/test splitting + AD analysis + visualizations\n",
    "#    - AD-Only: If splits exist, only run applicability domain analysis\n",
    "#\n",
    "# 3. Applicability Domain (AD) Modes:\n",
    "#    - Strict: Conservative predictions only within training space\n",
    "#    - Flexible: Balanced approach for practical applications\n",
    "#    - Adaptive: Dynamic thresholds based on local density\n",
    "#\n",
    "# 4. Generated Outputs:\n",
    "#    - Train/test splits for 9 different strategies (rm, sc, cs, cl, pc, ac, sa, ti, en)\n",
    "#    - Molecular fingerprints and descriptors\n",
    "#    - AD analysis results and visualizations\n",
    "#    - Statistical summaries and decision reports\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Output directory for analysis results\n",
    "output_dir = \"result/1_preprocess_enhanced\"\n",
    "\n",
    "# IMPORTANT: NEVER touch the data/ directory - it contains original data!\n",
    "# Train/test splits will be saved in the output directory\n",
    "\n",
    "# Option to force full analysis (set to True to run full analysis)\n",
    "FORCE_FULL_ANALYSIS = True  # Change this to False if you want to keep existing results\n",
    "\n",
    "# Clean up ONLY output directory if forcing full analysis\n",
    "if FORCE_FULL_ANALYSIS and os.path.exists(output_dir):\n",
    "    print(f\"üóëÔ∏è Removing existing output directory: {output_dir}\")\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(\"‚úì Output directory cleaned. Running full analysis...\")\n",
    "\n",
    "# Check if train and test directories already exist in output dir\n",
    "train_dir = os.path.join(output_dir, \"train\")\n",
    "test_dir = os.path.join(output_dir, \"test\")\n",
    "\n",
    "if os.path.exists(train_dir) and os.path.exists(test_dir) and not FORCE_FULL_ANALYSIS:\n",
    "    print(\"‚úì Train and test data exist in output directory. Running AD analysis only...\")\n",
    "    print(f\"  - Train directory: {train_dir}\")\n",
    "    print(f\"  - Test directory: {test_dir}\")\n",
    "    print(\"\\n‚ö†Ô∏è To run full analysis, set FORCE_FULL_ANALYSIS = True\")\n",
    "    \n",
    "    # [Previous AD-only analysis code would go here]\n",
    "    print(\"\\n‚ùå AD-only analysis is not fully implemented yet.\")\n",
    "    print(\"Please set FORCE_FULL_ANALYSIS = True to run complete analysis.\")\n",
    "    \n",
    "else:\n",
    "    print(\"Starting full analysis (including train/test split)...\")\n",
    "    print(\"\\n‚ö†Ô∏è IMPORTANT: Original data in 'data/' directory will NOT be modified!\")\n",
    "    \n",
    "    # Run complete analysis with all results saved in output_dir\n",
    "    analyzer = run_enhanced_analysis(\n",
    "        df_dict=df_dict,\n",
    "        test_only_datasets=test_only_datasets,\n",
    "        output_dir=output_dir,\n",
    "        performance_mode=False,\n",
    "        ad_mode='flexible',  # Default mode for initial analysis\n",
    "        ad_analysis_mode='all',  # This will analyze all modes: strict, flexible, adaptive\n",
    "        max_samples=30000,\n",
    "        show_recommendations=False,\n",
    "        enable_reliability_scoring=False\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ FULL ANALYSIS COMPLETED!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nAll results saved to: {output_dir}/\")\n",
    "    print(\"\\nGenerated outputs:\")\n",
    "    print(\"  - Train/test splits (in output directory)\")\n",
    "    print(\"  - Molecular features and descriptors\")\n",
    "    print(\"  - AD analysis for all modes (strict, flexible, adaptive)\")\n",
    "    print(\"  - Statistical analysis\")\n",
    "    print(\"  - Comprehensive visualizations\")\n",
    "    print(\"  - Decision reports for each AD mode\")\n",
    "    print(\"\\n‚úÖ Original data in 'data/' directory is preserved!\")\n",
    "# 189m 32s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764b54c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\\nüìã Available datasets:\")\n",
    "# for idx, (name, df) in enumerate(df_dict.items()):\n",
    "#     valid_samples = df.filter(\n",
    "#         (pl.col(\"target_x\").is_not_null()) & \n",
    "#         (pl.col(\"target_y\").is_not_null())\n",
    "#     ).shape[0]\n",
    "#     print(f\" [{idx}] {name}: {df.shape[0]} total, {valid_samples} valid samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96b520e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14cad8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_only_datasets=['SAMPL','Lipophilicity','curated-solubility-dataset','BigSolDB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fffdb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzer = run_enhanced_analysis(\n",
    "#     df_dict=df_dict,\n",
    "#     test_only_datasets=test_only_datasets,\n",
    "#     output_dir=\"result/1_preprocess\",\n",
    "#     performance_mode=False,\n",
    "#     ad_analysis_mode='all', # ('strict', 'flexible', 'adaptive')\n",
    "#     max_samples=30000,\n",
    "#     show_recommendations=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798478a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
